{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from attention import AttentionLayer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_latest_checkpoint(directory):\n",
    "    checkpoints = [file for file in os.listdir(directory) if file.startswith(\"checkpoint-\") and file.endswith(\".model.keras\")]\n",
    "    if not checkpoints:\n",
    "        return None  # No checkpoint files found\n",
    "    latest_checkpoint = max(checkpoints)\n",
    "    return os.path.join(directory, latest_checkpoint)\n",
    "\n",
    "checkpoint_directory = \"./outputs/checkpoints/\"\n",
    "latest_checkpoint_path = get_latest_checkpoint(checkpoint_directory)\n",
    "model_path = latest_checkpoint_path\n",
    "tokenizer_path = \"./outputs/tokenizer.json\"\n",
    "with open(tokenizer_path, 'r', encoding='utf-8') as f:\n",
    "    loaded_tokenizer_json = f.read()\n",
    "    tokenizer = tokenizer_from_json(loaded_tokenizer_json)\n",
    "# Load saved model\n",
    "model = keras.models.load_model(model_path)\n",
    "# # Rename the layer\n",
    "# layer_to_rename = model.get_layer('input_layer_1')\n",
    "# layer_to_rename._name = 'input_layer_unique_name'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "max_text_len=256 #word\n",
    "max_summary_len=128 #word\n",
    "batch_size = 60\n",
    "latent_dim = 300\n",
    "embedding_dim = 100\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "#======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"text_summary_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text'][0:100]\n",
    "summary = df['summary'][0:100]\n",
    "\n",
    "text_sequence = pad_sequences(tokenizer.texts_to_sequences(text), maxlen=max_text_len, padding='post')\n",
    "summary_sequence = pad_sequences(tokenizer.texts_to_sequences(summary), maxlen=max_summary_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = model.layers[0]\n",
    "encoder_inputs = model.inputs[0]\n",
    "# decoder_inputs = model.layers[3]\n",
    "decoder_inputs = model.inputs[1]\n",
    "dec_emb_layer=model.layers[5]\n",
    "encoder_outputs, state_h, state_c = model.layers[6].output\n",
    "decoder_lstm = model.layers[7]\n",
    "attn_layer = model.layers[8]\n",
    "decoder_dense = model.layers[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name=\"input_asdasd\")\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name=\"input_asaddfg\")\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim), name=\"input_asd5522d\")\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=tokenizer.index_word\n",
    "reverse_source_word_index=tokenizer.index_word\n",
    "target_word_index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(text_sequence[i]))\n",
    "    print(\"Original summary:\",seq2summary(summary_sequence[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(text_sequence[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
